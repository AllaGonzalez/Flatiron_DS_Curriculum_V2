{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Coefficient of Determination - Lab\n", "\n", "## Introduction\n", "In the previous lesson, we looked at the Coefficient of Determination, what it means and how it is calculated. In this lesson, we shall use the R-Squared formula to calculate it in python and numpy. \n", "\n", "## Objectives\n", "\n", "You will be able to:\n", "\n", "* Mathematically calculate R-Squared using a toy dataset\n", "\n", "* Calculate the coefficient of determination (R-Squared) for a given regression line\n", "\n", "* Interpret the value of R-Squared\n", "\n", "\n", "## Let's get started\n", "\n", "Once a regression model is created, we need to decide how \"accurate\" the regression line is to some degree. \n", "\n", "\n", "Here is the equation for R-Squared or the Coefficient of Determination again: \n", "\n", "$$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}} = 1- \\dfrac{\\sum_i(y_i - \\hat y_i)^2}{\\sum_i(y_i - \\overline y_i)^2} $$\n", " \n", " Note that this is also equal to:\n", "\n", "$$ R^2 = 1- \\dfrac{SS_{RES}}{SS_{TOT}}=\\dfrac{SS_{EXP}}{SS_{TOT}} $$\n", "where\n", "\n", "- $SS_{TOT} = \\sum_i(y_i - \\overline y_i)^2$ $\\rightarrow$ Total Sum of Squares  \n", "-  $SS_{EXP} = \\sum_i(\\hat y_i - \\overline y_i)^2$ $\\rightarrow$  Explained Sum of Squares\n", "- $SS_{RES}= \\sum_i(y_i - \\hat y_i)^2 $ $\\rightarrow$ Residual Sum of Squares\n", "\n", "Recall that the objective of $R^2$ is to learn how much of the error is a result in variation in the data features, as opposed to being a result of the regression line being a poor fit.\n", "\n", "## Programming R-Squared\n", "\n", "Let's calculate R-Squared in Python. The first step would be to calculate the Squared Error. Remember that the Squared Error is the Residual Sum of Squares of the difference between a given line and the actual data points.\n", "\n", "Create a function `sq_err()` that takes in y points for 2 arrays, calculates the difference corresponding elements of these arrays, squares, and sums all the differences. The function should return the RSS value you saw earlier."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate sum of squared errors between regression and mean line \n", "import numpy as np\n", "\n", "def sq_err(y_a, y_b):\n", "    \"\"\"\n", "    input\n", "    y_a : true y values\n", "    y_b : regression line\n", "\n", "    \n", "    return\n", "    squared error between regression and true line (ss_tot)\n", "    \"\"\"\n", "    pass\n", "\n", "# Check the output with some toy data\n", "Y_a = np.array([1,3,5,7])\n", "Y_b = np.array([1,4,5,8])\n", "\n", "sq_err(Y_a, Y_b)\n", "\n", "# 2"]}, {"cell_type": "markdown", "metadata": {}, "source": ["Squared error, as calculated above is only a part of the coefficient of determination, Let's now build a function that uses `sq_err()` function above to calculate the value of R-Squared by first calculating SSE, then use this same function to calculate SST (use the mean of $y$ instead of the regression line), and then plug in these values into the R-Squared formula. Perform the following tasks\n", "* Calculate the mean of the `y_real`\n", "* Calculate SSE using `sq_err()`\n", "* Calculate SST using `sq_err()`\n", "* Calculate R-Squared from above values using the given formula\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Calculate Y_mean , squared error for regression and mean line , and calculate r-squared\n", "\n", "def r_squared(y_real, y_predicted):\n", "    \"\"\"\n", "    input\n", "    y_real: real values\n", "    y_predicted: regression values\n", "    \n", "    return\n", "    r_squared value\n", "    \"\"\"\n", "    pass\n", "\n", "# Check the output with some toy data\n", "Y = np.array([1,3,5,7])\n", "Y_pred = np.array([1,5,5,10])\n", "\n", "r_squared(Y, Y_pred)\n", "\n", "# 0.35"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This R-Squared value is very low, but remember that it wasn't from real data. So now, we have quite a few functions for calculating slope, intercept, best-fit line, plotting and calculating R-squared. In the next lab, you'll put these all together to run a complete regression experiment."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "In this lesson, you learned how to calculate the R-Squared value in python and numpy. In the next lab, you will put all the functions from the last few labs together to create a complete DIY regression experiment. "]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}