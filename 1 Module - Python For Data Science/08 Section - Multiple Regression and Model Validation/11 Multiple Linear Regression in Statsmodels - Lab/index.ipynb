{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Multiple Linear Regression in Statsmodels - Lab"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Introduction\n", "In this lab, you'll practice fitting a multiple linear regression model on our Boston Housing Data set!"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Objectives\n", "You will be able to:\n", "* Run linear regression on Boston Housing dataset with all the predictors\n", "* Interpret the parameters of the multiple linear regression model"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## The Boston Housing Data"]}, {"cell_type": "markdown", "metadata": {}, "source": ["We pre-processed the Boston Housing Data again. This time, however, we did things slightly different:\n", "- We dropped \"ZN\" and \"NOX\" completely\n", "- We categorized \"RAD\" in 3 bins and \"TAX\" in 4 bins\n", "- We transformed \"RAD\" and \"TAX\" to dummy variables and dropped the first variable.\n", "- We used min-max-scaling on \"B\", \"CRIM\" and \"DIS\" (and logtransformed all of them first, except \"B\")\n", "- We used standardization on \"AGE\", \"INDUS\", \"LSTAT\" and \"PTRATIO\" (and logtransformed all of them first, except for \"AGE\") "]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "from sklearn.datasets import load_boston\n", "boston = load_boston()\n", "\n", "boston_features = pd.DataFrame(boston.data, columns = boston.feature_names)\n", "boston_features = boston_features.drop([\"NOX\",\"ZN\"],axis=1)\n", "\n", "# first, create bins for based on the values observed. 3 values will result in 2 bins\n", "bins = [0, 6,  24]\n", "bins_rad = pd.cut(boston_features['RAD'], bins)\n", "bins_rad = bins_rad.cat.as_unordered()\n", "\n", "# first, create bins for based on the values observed. 4 values will result in 3 bins\n", "bins = [0, 270, 360, 712]\n", "bins_tax = pd.cut(boston_features['TAX'], bins)\n", "bins_tax = bins_tax.cat.as_unordered()\n", "\n", "tax_dummy = pd.get_dummies(bins_tax, prefix=\"TAX\", drop_first=True)\n", "rad_dummy = pd.get_dummies(bins_rad, prefix=\"RAD\", drop_first=True)\n", "boston_features = boston_features.drop([\"RAD\",\"TAX\"], axis=1)\n", "boston_features = pd.concat([boston_features, rad_dummy, tax_dummy], axis=1)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["age = boston_features[\"AGE\"]\n", "b = boston_features[\"B\"]\n", "logcrim = np.log(boston_features[\"CRIM\"])\n", "logdis = np.log(boston_features[\"DIS\"])\n", "logindus = np.log(boston_features[\"INDUS\"])\n", "loglstat = np.log(boston_features[\"LSTAT\"])\n", "logptratio = np.log(boston_features[\"PTRATIO\"])\n", "\n", "# minmax scaling\n", "boston_features[\"B\"] = (b-min(b))/(max(b)-min(b))\n", "boston_features[\"CRIM\"] = (logcrim-min(logcrim))/(max(logcrim)-min(logcrim))\n", "boston_features[\"DIS\"] = (logdis-min(logdis))/(max(logdis)-min(logdis))\n", "\n", "#standardization\n", "boston_features[\"AGE\"] = (age-np.mean(age))/np.sqrt(np.var(age))\n", "boston_features[\"INDUS\"] = (logindus-np.mean(logindus))/np.sqrt(np.var(logindus))\n", "boston_features[\"LSTAT\"] = (loglstat-np.mean(loglstat))/np.sqrt(np.var(loglstat))\n", "boston_features[\"PTRATIO\"] = (logptratio-np.mean(logptratio))/(np.sqrt(np.var(logptratio)))"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["boston_features.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Run an linear model in Statsmodels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Run the same model in Scikit-learn"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Your code here - Check that the coefficients and intercept are the same as those from Statsmodels"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Interpret the coefficients for PTRATIO, PTRATIO, LSTAT"]}, {"cell_type": "markdown", "metadata": {}, "source": ["- CRIM: per capita crime rate by town\n", "- INDUS: proportion of non-retail business acres per town\n", "- CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n", "- RM: average number of rooms per dwelling\n", "- AGE: proportion of owner-occupied units built prior to 1940\n", "- DIS: weighted distances to five Boston employment centres\n", "- RAD: index of accessibility to radial highways\n", "- TAX: full-value property-tax rate per $10,000\n", "- PTRATIO: pupil-teacher ratio by town\n", "- B: 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n", "- LSTAT: % lower status of the population"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Predict the house price given the following characteristics (before manipulation!!)\n", "\n", "Make sure to transform your variables as needed!\n", "\n", "- CRIM: 0.15\n", "- INDUS: 6.07\n", "- CHAS: 1        \n", "- RM:  6.1\n", "- AGE: 33.2\n", "- DIS: 7.6\n", "- PTRATIO: 17\n", "- B: 383\n", "- LSTAT: 10.87\n", "- RAD: 8\n", "- TAX: 284"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Summary\n", "Congratulations! You've fitted your first multiple linear regression model on the Boston Housing Data."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.6"}}, "nbformat": 4, "nbformat_minor": 2}