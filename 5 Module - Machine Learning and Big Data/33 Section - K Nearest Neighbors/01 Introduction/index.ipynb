{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors (KNN) Intro\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this section you'll look at an intuitive algorithm known as K-Nearest Neighbors. KNN is an effective classification and regression algorithm that uses nearby points in order to generate a prediction. \n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "* Explain what KNN stands for\n",
    "* Explain the KNN algorithm at a high level\n",
    "\n",
    "## KNN \n",
    "\n",
    "The K-Nearest Neighbors algorithm works as follows:\n",
    "1. Choose a point \n",
    "2. Find the K-Nearest points\n",
    "    1. K is a predefined user constant such as 1,2,3,5 or 10.\n",
    "3. Predict a label for the current point:\n",
    "    1. Classification - Take the most common class of the k neighbors\n",
    "    2. Regression - Take the average target metric of the k neighbors\n",
    "    3. Both classification or regression can also be modified to use weighted averages based on the distance of the neighbors\n",
    "\n",
    "## Distance Metrics\n",
    "\n",
    "An incredibly important decision when using the KNN algorithm is determining an appropriate distance metric. As one might expect, this makes a monumental impact to the output of the algorithm. While there are additional distance metrics, such as cosine distance which are left out, you'll get a solid introduction to distance metrics by looking at the standard Euclidean distance and its more generic counterpart, Minkowski distance.\n",
    "\n",
    "## K-Means\n",
    "\n",
    "While outside the scope of this section, it is worth mentioning the related K-Means algorithm which uses similar principles as KNN but serves as an unsupervised learning clustering algorithm. In the K-Means algorithm, K represents the number of clusters rather then the number of neighbors. Unlike KNN, K-means is an iterative algorithm which repeats until convergence. Nonetheless, its underlying principle is the same, in that it groups data points together using a distance metric in order to create homogeneous groupings.\n",
    "\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this introduction, you got a brief overview of the KNN algorithm and distance metrics. From here, you'll jump straight in to get further details of KNN, practice coding your own implementation and then get an introduction to use pre-built tools within sci-kit learn."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
