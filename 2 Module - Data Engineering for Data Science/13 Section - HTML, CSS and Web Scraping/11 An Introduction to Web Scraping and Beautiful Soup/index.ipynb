{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Introduction to Web Scraping and Beautiful Soup\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Now that you've gotten a small taste of web development, it's time to practice reverse engineering and extracting data from the web!\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "* Load an HTML document\n",
    "* Select specific elements from the DOM\n",
    "\n",
    "## Web Page Introduction: **The DOM + HTML**\n",
    "\n",
    "Before starting scraping, let's review the structure of HTML codes.\n",
    "\n",
    "As you know, \"The Document Object Model (DOM) is a programming interface for HTML and XML documents. It represents the page so that programs can change the document structure, style, and content. The DOM represents the document as nodes and objects. That way, programming languages can connect to the page.\" Amongst other things, this allows programming languages such as javascript to interactively change the page and HTML!  \n",
    "\n",
    "What you'll see is the DOM and HTML create a hierarchy of elements. This structure and the underlying elements can be navigated similar to a family tree which is one of Beautiful Soups main mechanisms for navigation; once you select a specific element within a page you can then navigate to successive elements using methods to retrieve related tags including a tags sibling, parent or descendants.\n",
    "  \n",
    "To learn more about the DOM see:  \n",
    "https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model/Introduction\n",
    "\n",
    "<img src=\"images/DOM-model.svg.png\" width=\"500\">\n",
    "\n",
    "## Beautiful Soup   \n",
    "https://www.crummy.com/software/BeautifulSoup/bs4/doc/   \n",
    "\n",
    "Beautiful Soup is a Python library designed for quick scraping projects. It allows you to select and navigate the tree-like structure of HTML documents, searching for particular tags, attributes or ids. It also allows you to then further traverse the HTML documents through relations like children or siblings. In other words, with beautiful soup, you could first select a specific div tag and then search through all of its nested tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An example webpage\n",
    "\n",
    "Let's take a look at a very simple HTML page to see how you could select various elements using Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   The Dormouse's story\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    The Dormouse's story\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   Once upon a time there were three little sisters; and their names were\n",
      "   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "    Elsie\n",
      "   </a>\n",
      "   ,\n",
      "   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "    Lacie\n",
      "   </a>\n",
      "   and\n",
      "   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link2\">\n",
      "    Tillie\n",
      "   </a>\n",
      "   ; and they lived at the bottom of a well.\n",
      "  </p>\n",
      "  <p class=\"story\">\n",
      "   ...\n",
      "  </p>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "with open('sample_page.html') as f:\n",
    "    soup = BeautifulSoup(f, 'html.parser')\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A few introductory Beautiful Soup Selections..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>\n",
      "    The Dormouse's story\n",
      "   </title>\n",
      "title\n",
      "\n",
      "    The Dormouse's story\n",
      "   \n",
      "head\n",
      "<p class=\"title\">\n",
      "<b>\n",
      "     The Dormouse's story\n",
      "    </b>\n",
      "</p>\n",
      "['title']\n",
      "<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "     Elsie\n",
      "    </a>\n",
      "[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\n",
      "     Elsie\n",
      "    </a>, <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\n",
      "     Lacie\n",
      "    </a>, <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link2\">\n",
      "     Tillie\n",
      "    </a>]\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(soup.title)\n",
    "# <title>The Dormouse's story</title>\n",
    "\n",
    "print(soup.title.name)\n",
    "# u'title'\n",
    "\n",
    "print(soup.title.string)\n",
    "# u'The Dormouse's story'\n",
    "\n",
    "print(soup.title.parent.name)\n",
    "# u'head'\n",
    "\n",
    "print(soup.p)\n",
    "# <p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "print(soup.p['class'])\n",
    "# u'title'\n",
    "\n",
    "print(soup.a)\n",
    "# <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n",
    "\n",
    "print(soup.find_all('a'))\n",
    "# [<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n",
    "#  <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n",
    "\n",
    "print(soup.find(id=\"link3\"))\n",
    "# <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings and Precautions\n",
    "\n",
    "While web scraping is a powerful tool, it can also lead you into ethical and legal gray areas. To start, it is possible to make hundreds of requests a second to a website. Browsing at superhuman speeds such as this is apt to get noticed. Large volumes of requests such as this are apt to bog down a website's servers and in extreme cases could be considered a denial of service attack. Similarly, any website requiring login may contain information that is thereby not considered public and scraping said websites could leave you in legal jeopardy. Use your best judgment when scraping and exercise precautions. Having your IP address blocked from your favorite website, for example, could prove to be quite an annoyance.\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "Beautiful soup is the preliminary tool for web scraping. That said, there are more complex examples where you may wish to either scrape larger amounts of data through full-on web crawling, or trickier examples involving javascript. For these and other scenarios, alternative tools such as selenium and scrapy are worth investigating.\n",
    "\n",
    "#### Beautiful Soup - a good g- to tool for parsing the DOM\n",
    "https://www.crummy.com/software/BeautifulSoup/?\n",
    "\n",
    "#### Selenium - Browser automation (useful when you need to interact with javascript for more complex scraping)\n",
    "https://www.seleniumhq.org/\n",
    "\n",
    "#### Scrapy - another package for scraping larger datasets at scale\n",
    "https://scrapy.org/\n",
    "\n",
    "## Summary\n",
    "You should now have a brief intro to web scraping! The possibilities are nearly endless with what you can do. That said, be careful, as mentioned."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
